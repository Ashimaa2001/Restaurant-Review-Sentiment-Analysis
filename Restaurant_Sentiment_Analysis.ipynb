{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing files and Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ashim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('C:\\\\Users\\\\ashim\\\\Downloads\\\\reviews.tsv', delimiter = '\\t')\n",
    "\n",
    "import re   #checks if a particular string matches a given regular expression \n",
    "import nltk    #Natural Language Toolkit; for building Python programs to work with human language data\n",
    "\n",
    "nltk.download('stopwords')    \n",
    "\n",
    "from nltk.corpus import stopwords   #collection of commonly used words (such as “the”, “a”, “an”, “in”) \n",
    "from nltk.stem.porter import PorterStemmer   #removing the commoner inflexion endings from words, extract root word( ed,est)\n",
    "ps = PorterStemmer()   \n",
    "\n",
    "all_stopwords = stopwords.words('english')  #list of all the English stop words supported by NLTK\n",
    "all_stopwords.remove('not')   #Removing not from stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "\n",
    "for i in range(0, 900):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])   #[^_] negates a character match inside square brackets, i.e. the characters apart from a-z and A-Z and substitute them with a blank \" \"\n",
    "  review = review.lower()   # returns the lowercased strings\n",
    "  review = review.split()   # splits a string into a list\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)  \n",
    "  words.append(review)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "cv = CountVectorizer(max_features = 1420)   #CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(words).toarray()   \n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting into Train and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter.ttk import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for sentiment prediction using the following models-\n",
    "- Support Vector Machine\n",
    "- MultiNomial Naive Bayes\n",
    "- Bernoulli Naive Bayes\n",
    "- Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(root, input):\n",
    "    \n",
    "    from sklearn import svm\n",
    "    classifier= svm.SVC(kernel=\"linear\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred= classifier.predict(X_test)\n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        gaus= Label(root, text='Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.4)\n",
    "    else:\n",
    "        gaus= Label(root, text='Good review', font=\"times 15\").place(relx= 0.45, rely=0.4)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinom(root, input):\n",
    "    \n",
    "    classifier = MultinomialNB(alpha=0.1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        Label(root, text='Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.5)\n",
    "    else:\n",
    "        Label(root, text='Good review', font=\"times 15\").place(relx= 0.45, rely=0.5)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli(root, input):\n",
    "\n",
    "    # Fitting Naive Bayes to the Training set\n",
    "    classifier = BernoulliNB(alpha=0.8)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        Label(root, text='Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.6)\n",
    "    else:\n",
    "        Label(root, text='Good review', font=\"times 15\").place(relx= 0.45, rely=0.6)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(root, input):\n",
    "    \n",
    "    # Fitting Logistic Regression to the Training set\n",
    "    classifier = linear_model.LogisticRegression(C=1.5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    data = [input]\n",
    "    vectorizer = cv.transform(data).toarray()\n",
    "    pred = classifier.predict(vectorizer)\n",
    "    if pred==0 :\n",
    "        log= Label(root,text= 'Bad  review', font=\"times 15\").place(relx= 0.45, rely=0.7)\n",
    "        \n",
    "    else:\n",
    "        log= Label(root,text= 'Good review', font=\"times 15\").place(relx= 0.45, rely=0.7)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for evaluating Accuracy, Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_acc(root):\n",
    "    from sklearn import svm\n",
    "    classifier= svm.SVC(kernel=\"linear\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred= classifier.predict(X_test)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "    \n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_acc(root):\n",
    "    classifier = MultinomialNB(alpha=0.1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "\n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bern_acc(root):\n",
    "    # Making the Confusion Matrix\n",
    "    classifier = BernoulliNB(alpha=0.8)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "\n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_acc(root):\n",
    "    classifier = linear_model.LogisticRegression(C=1.5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    score1 = accuracy_score(y_test,y_pred)\n",
    "    score2 = precision_score(y_test,y_pred)\n",
    "    score3= recall_score(y_test,y_pred)\n",
    "\n",
    "    Label(root,text= round(score1*100,2), relief=\"solid\").place(relx= 0.85, rely=0.45)\n",
    "    Label(root,text= round(score2*100,2), relief=\"solid\").place(relx= 0.85, rely=0.55)\n",
    "    Label(root,text= round(score3*100,2), relief=\"solid\").place(relx= 0.85, rely=0.65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2():\n",
    "    input = rev.get()\n",
    "    # print(input)\n",
    "    svm(main_window, input)\n",
    "    multinom(main_window, input)\n",
    "    bernoulli(main_window, input)\n",
    "    logistic(main_window, input)  \n",
    "\n",
    "def svm_acc2():\n",
    "    svm_acc(main_window)\n",
    "\n",
    "def mult_acc2():\n",
    "    mult_acc(main_window)\n",
    "\n",
    "def bern_acc2():\n",
    "    bern_acc(main_window)\n",
    "\n",
    "def log_acc2():\n",
    "    log_acc(main_window)\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "\n",
    "main_window= Tk()\n",
    "\n",
    "main_window.geometry(\"900x600\")\n",
    "main_window['background']='#99ff99'\n",
    "\n",
    "Label(main_window, text=\"Review Sentiment Predictor\", font=\"times 15 bold\").place(relx= 0.19, rely=0.08)\n",
    "\n",
    "Label(main_window, text=\"Enter a review:\", font=\"times 15 bold\").place(relx= 0.1, rely=0.2)\n",
    "\n",
    "rev= ttk.Entry(main_window,width=40)\n",
    "rev.place(relx=0.3, rely=0.2)\n",
    "\n",
    "Button(main_window,text=\"Submit\",command =evaluate2).place(relx=0.3, rely= 0.3)\n",
    "\n",
    "Label(main_window, text= \"Prediction using SVM Model\", font=\"times 15 bold\").place(relx=0.1, rely=0.4)\n",
    "Label(main_window, text= \"Prediction using Multinomial Model\", font=\"times 15 bold\",).place(relx=0.1, rely=0.5)\n",
    "Label(main_window, text= \"Prediction using Bernoulli Model\", font=\"times 15 bold\").place(relx=0.1, rely=0.6)\n",
    "Label(main_window, text= \"Prediction using Logistic Model\", font=\"times 15 bold\").place(relx=0.1, rely=0.7)\n",
    "\n",
    "Label(main_window, text = \"Check Accuracy of models\",font=\"times 15 bold\").place(relx= 0.65, rely= 0.08)\n",
    "\n",
    "Button(main_window, text = \"SVM\", command= svm_acc2).place(relx= 0.7, rely= 0.2)\n",
    "Button(main_window, text = \"Multinomial\", command= mult_acc2).place(relx= 0.7, rely= 0.3)\n",
    "Button(main_window, text = \"Bernoulli\", command=bern_acc2).place(relx= 0.8, rely= 0.2)\n",
    "Button(main_window, text = \"Logistic\",command= log_acc2).place(relx= 0.8, rely= 0.3)\n",
    "\n",
    "\n",
    "Label(main_window, text= \"Accuracy\", font=\"times 15 bold underline\").place(relx=0.67, rely=0.45)\n",
    "Label(main_window, text= \"Precision\", font=\"times 15 bold underline\").place(relx=0.67, rely=0.55)\n",
    "Label(main_window, text= \"Recall\", font=\"times 15 bold underline\").place(relx=0.67, rely=0.65)\n",
    "\n",
    "Label(main_window, text= \"%\", font=\"times 13 bold\").place(relx=0.9, rely=0.45)\n",
    "Label(main_window, text= \"%\", font=\"times 13 bold\").place(relx=0.9, rely=0.55)\n",
    "Label(main_window, text= \"%\", font=\"times 13 bold\").place(relx=0.9, rely=0.65)\n",
    "\n",
    "main_window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "\n",
    "The Model Evaluation Parameters used to analyse our model are-\n",
    "1. Accuracy- It is percentage deviation of predicted target with actual target.\n",
    "2. Precision- It tells us how many of the correctly predicted cases actually turned out to be positive.\n",
    "3. Recall- It is the proportion of positive data points that are correctly considered as positive, with respect to all data points.\n",
    "\n",
    "Using Support Vector Machine-\n",
    "* Accuracy is  77.22 %\n",
    "* Precision is  80.2\n",
    "* Recall is  79.41\n",
    "\n",
    "\n",
    "Using MultiNomial Naive Bayes-\n",
    "\n",
    "* Accuracy is 78.89 %\n",
    "* Precision is  81.37\n",
    "* Recall is  81.37\n",
    "\n",
    "\n",
    "Using Bernoulli Naive Bayes-\n",
    "\n",
    "* Accuracy is  76.11 %\n",
    "* Precision is  75.21\n",
    "* Recall is  86.27\n",
    "\n",
    "\n",
    "Using Logistic Regression-\n",
    "\n",
    "* Accuracy is  77.78 %\n",
    "* Precision is  78.7\n",
    "* Recall is  83.33\n",
    "\n",
    "From above, it is clear that-\n",
    "* Accuracy is best for MultiNomial Naive Bayes \n",
    "* Precision is best for MultiNomial Naive Bayes\n",
    "* Recall is best for Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c08fcd23c77bfb5ee56d1a6f1427620e609d2a5b71021227ea509b0443ab141b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
